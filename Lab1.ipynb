{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 Numpy CNN for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you are required to fill in the blanks with your code **independently** to complete the inference process of a CNN. Note that there's a bonus at the end of this lab.\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "**1. Complete the codes independently.**\n",
    "\n",
    "**2. Make sure your results are reproducible.**\n",
    "\n",
    "**3. Do not change the structure of the CNN and the given codes.**\n",
    "\n",
    "**4. Do not add additional libraries.**\n",
    "\n",
    "**Submission**\n",
    "\n",
    "**1. Please submit only this ipynb file via Blackboard.**\n",
    "\n",
    "**2. Name the ipynb file as \"StudentID_StudentName\".**\n",
    "\n",
    "**3. Submit before Oct. 22nd 23:59:59.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple CNN that classifies CIFAR images.\n",
    "The network provided is similar to LeNet-5, and it has the following architecture:\n",
    "\n",
    "**Layer** | **Type** | **Input Shape** | **Output Shape** | **Activation**\n",
    "--- | --- | --- | --- | ---\n",
    "conv1 | Convolutional | 3x32x32 | 12x28x28 | ReLU \n",
    "pool1 | Max pool | 12x28x28 | 12x14x14 | None                \n",
    "conv2 | Convolutional | 12x14x14 | 32x12x12 | ReLU                \n",
    "pool2 | Max pool | 32x12x12 | 32x6x6 | None                \n",
    "fc1 | Fully-connected | 1152 | 256 | ReLU                \n",
    "fc2 | Fully-connected | 256 | 64 | ReLU                \n",
    "fc3 | Fully-connected | 64 | 10 | None                \n",
    "\n",
    "Next, we will build convolution, relu, max-pooling and fully-connected layers using **numpy** respectively (only forward propagation is required for inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self,input):\n",
    "        # TODO (5 pts) \n",
    "        # forward propagation for relu layer\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:  \n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride, padding):   \n",
    "        self.input_channels = input_channels   \n",
    "        self.kernel_size = kernel_size  \n",
    "        self.stride = stride\n",
    "        self.padding = padding \n",
    "  \n",
    "    def forward(self, x, weight):  \n",
    "        \"\"\"    \n",
    "        input x: (N, C, H, W) [batchsize, input channels, x_height, x_width]\n",
    "        input w: (K, C, R, S) [output channels, input channels, w_height, w_width] \n",
    "        output: (N, K, P, Q) [batchsize, output channels, output_height, output_width]\n",
    "        \"\"\"  \n",
    "        N, C, H, W = x.shape\n",
    "        K, C, R, S = weight.shape\n",
    "        \n",
    "        # TODO (5 pts)  \n",
    "        # complete padding operation\n",
    "        \n",
    "        \n",
    "        # TODO (5 pts)  \n",
    "        # compute output size using self.padding and self.stride\n",
    "        P = \n",
    "        Q = \n",
    "        \n",
    "        output = np.zeros((N, K, P, Q)) \n",
    "        # TODO (20 pts)\n",
    "        # complete convolution operation\n",
    "        \n",
    "        return output\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling2D:  \n",
    "    def __init__(self, pool_size=(2, 2), stride=2):  \n",
    "        self.pool_size = pool_size  \n",
    "        self.stride = stride  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        \"\"\"    \n",
    "        input x: (N, C, H, W) [batchsize, input channels, x_height, x_width]\n",
    "        output: (N, C, pooled_height, pooled_width)\n",
    "        \"\"\"  \n",
    "        N, C, H, W = x.shape  \n",
    "        # TODO (5 pts) \n",
    "        # compute output size using self.pool_size and self.stride\n",
    "        pooled_height = \n",
    "        pooled_width = \n",
    "  \n",
    "        output = np.zeros((N, C, pooled_height, pooled_width))  \n",
    "        # TODO (10 pts)\n",
    "        # complete max-pooling operation \n",
    "  \n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fclayer():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def forward(self, x, weight):   \n",
    "        # TODO (10 pts)\n",
    "        # complete forward propagation of fully-connected layer\n",
    "        \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# load trained parameters\n",
    "ckpt = torch.load('./model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_inf(x,ckpt):\n",
    "    # TODO (20 pts)\n",
    "    # build the CNN network using classes above\n",
    "    \n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "from skimage.transform import resize\n",
    "\n",
    "# In this lab we will only infer 1 picture from CIFAR-10 datasets to save running time\n",
    "# you can try different pictures in ./pictures\n",
    "input_image = imageio.imread('./pictures/bird1.png')\n",
    "\n",
    "# TODO (5 pts)\n",
    "# normalize the pixel into [0,1]\n",
    "image = \n",
    "\n",
    "# TODO (5 pts)\n",
    "# alter the size of the pixel matrix from (32,32,3) to (1,3,32,32) to fit convolution layer\n",
    "image = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (5 pts)\n",
    "# inference using lenet_inf created above\n",
    "# note that the inference process of 1 picture using numpy may take more than 20 minutes\n",
    "output = \n",
    "label = np.argmax(output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# visualize the picture to be classified\n",
    "plt.imshow(input_image)\n",
    "print(\"Predicted label:\",label)\n",
    "print(\"Ground truth: 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Calculate the number of computations and parameters. Visualize your results directly in the outputs of your codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your answer here.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
